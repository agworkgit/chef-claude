{"ast":null,"code":"const taskData = {\n  datasets: [{\n    // TODO write proper description\n    description: \"A famous question answering dataset based on English articles from Wikipedia.\",\n    id: \"squad_v2\"\n  }, {\n    // TODO write proper description\n    description: \"A dataset of aggregated anonymized actual queries issued to the Google search engine.\",\n    id: \"natural_questions\"\n  }],\n  demo: {\n    inputs: [{\n      label: \"Question\",\n      content: \"Which name is also used to describe the Amazon rainforest in English?\",\n      type: \"text\"\n    }, {\n      label: \"Context\",\n      content: \"The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle\",\n      type: \"text\"\n    }],\n    outputs: [{\n      label: \"Answer\",\n      content: \"Amazonia\",\n      type: \"text\"\n    }]\n  },\n  metrics: [{\n    description: \"Exact Match is a metric based on the strict character match of the predicted answer and the right answer. For answers predicted correctly, the Exact Match will be 1. Even if only one character is different, Exact Match will be 0\",\n    id: \"exact-match\"\n  }, {\n    description: \" The F1-Score metric is useful if we value both false positives and false negatives equally. The F1-Score is calculated on each word in the predicted sequence against the correct answer\",\n    id: \"f1\"\n  }],\n  models: [{\n    description: \"A robust baseline model for most question answering domains.\",\n    id: \"deepset/roberta-base-squad2\"\n  }, {\n    description: \"Small yet robust model that can answer questions.\",\n    id: \"distilbert/distilbert-base-cased-distilled-squad\"\n  }, {\n    description: \"A special model that can answer questions from tables.\",\n    id: \"google/tapas-base-finetuned-wtq\"\n  }],\n  spaces: [{\n    description: \"An application that can answer a long question from Wikipedia.\",\n    id: \"deepset/wikipedia-assistant\"\n  }],\n  summary: \"Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document. Some question answering models can generate answers without context!\",\n  widgetModels: [\"deepset/roberta-base-squad2\"],\n  youtubeId: \"ajPx5LwJD-I\"\n};\nexport default taskData;","map":{"version":3,"names":["taskData","datasets","description","id","demo","inputs","label","content","type","outputs","metrics","models","spaces","summary","widgetModels","youtubeId"],"sources":["/Users/agmacbook/Documents/Courses/Meta - Full Stack/Exercises/meta_fullstack_exercises/6_react_basics/12_review/13_chef_claude/node_modules/@huggingface/tasks/dist/esm/tasks/question-answering/data.js"],"sourcesContent":["const taskData = {\n    datasets: [\n        {\n            // TODO write proper description\n            description: \"A famous question answering dataset based on English articles from Wikipedia.\",\n            id: \"squad_v2\",\n        },\n        {\n            // TODO write proper description\n            description: \"A dataset of aggregated anonymized actual queries issued to the Google search engine.\",\n            id: \"natural_questions\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Question\",\n                content: \"Which name is also used to describe the Amazon rainforest in English?\",\n                type: \"text\",\n            },\n            {\n                label: \"Context\",\n                content: \"The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Answer\",\n                content: \"Amazonia\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Exact Match is a metric based on the strict character match of the predicted answer and the right answer. For answers predicted correctly, the Exact Match will be 1. Even if only one character is different, Exact Match will be 0\",\n            id: \"exact-match\",\n        },\n        {\n            description: \" The F1-Score metric is useful if we value both false positives and false negatives equally. The F1-Score is calculated on each word in the predicted sequence against the correct answer\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            description: \"A robust baseline model for most question answering domains.\",\n            id: \"deepset/roberta-base-squad2\",\n        },\n        {\n            description: \"Small yet robust model that can answer questions.\",\n            id: \"distilbert/distilbert-base-cased-distilled-squad\",\n        },\n        {\n            description: \"A special model that can answer questions from tables.\",\n            id: \"google/tapas-base-finetuned-wtq\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can answer a long question from Wikipedia.\",\n            id: \"deepset/wikipedia-assistant\",\n        },\n    ],\n    summary: \"Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document. Some question answering models can generate answers without context!\",\n    widgetModels: [\"deepset/roberta-base-squad2\"],\n    youtubeId: \"ajPx5LwJD-I\",\n};\nexport default taskData;\n"],"mappings":"AAAA,MAAMA,QAAQ,GAAG;EACbC,QAAQ,EAAE,CACN;IACI;IACAC,WAAW,EAAE,+EAA+E;IAC5FC,EAAE,EAAE;EACR,CAAC,EACD;IACI;IACAD,WAAW,EAAE,uFAAuF;IACpGC,EAAE,EAAE;EACR,CAAC,CACJ;EACDC,IAAI,EAAE;IACFC,MAAM,EAAE,CACJ;MACIC,KAAK,EAAE,UAAU;MACjBC,OAAO,EAAE,uEAAuE;MAChFC,IAAI,EAAE;IACV,CAAC,EACD;MACIF,KAAK,EAAE,SAAS;MAChBC,OAAO,EAAE,+EAA+E;MACxFC,IAAI,EAAE;IACV,CAAC,CACJ;IACDC,OAAO,EAAE,CACL;MACIH,KAAK,EAAE,QAAQ;MACfC,OAAO,EAAE,UAAU;MACnBC,IAAI,EAAE;IACV,CAAC;EAET,CAAC;EACDE,OAAO,EAAE,CACL;IACIR,WAAW,EAAE,sOAAsO;IACnPC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,2LAA2L;IACxMC,EAAE,EAAE;EACR,CAAC,CACJ;EACDQ,MAAM,EAAE,CACJ;IACIT,WAAW,EAAE,8DAA8D;IAC3EC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,mDAAmD;IAChEC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,wDAAwD;IACrEC,EAAE,EAAE;EACR,CAAC,CACJ;EACDS,MAAM,EAAE,CACJ;IACIV,WAAW,EAAE,gEAAgE;IAC7EC,EAAE,EAAE;EACR,CAAC,CACJ;EACDU,OAAO,EAAE,oNAAoN;EAC7NC,YAAY,EAAE,CAAC,6BAA6B,CAAC;EAC7CC,SAAS,EAAE;AACf,CAAC;AACD,eAAef,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}