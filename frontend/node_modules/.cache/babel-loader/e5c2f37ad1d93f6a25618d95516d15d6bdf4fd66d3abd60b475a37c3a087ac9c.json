{"ast":null,"code":"const taskData = {\n  datasets: [{\n    // TODO write proper description\n    description: \"Dataset from 12M image-text of Reddit\",\n    id: \"red_caps\"\n  }, {\n    // TODO write proper description\n    description: \"Dataset from 3.3M images of Google\",\n    id: \"datasets/conceptual_captions\"\n  }],\n  demo: {\n    inputs: [{\n      filename: \"savanna.jpg\",\n      type: \"img\"\n    }],\n    outputs: [{\n      label: \"Detailed description\",\n      content: \"a herd of giraffes and zebras grazing in a field\",\n      type: \"text\"\n    }]\n  },\n  metrics: [],\n  models: [{\n    description: \"Strong OCR model.\",\n    id: \"allenai/olmOCR-7B-0725\"\n  }, {\n    description: \"Powerful image captioning model.\",\n    id: \"fancyfeast/llama-joycaption-beta-one-hf-llava\"\n  }],\n  spaces: [{\n    description: \"SVG generator app from images.\",\n    id: \"multimodalart/OmniSVG-3B\"\n  }, {\n    description: \"An application that converts documents to markdown.\",\n    id: \"numind/NuMarkdown-8B-Thinking\"\n  }, {\n    description: \"An application that can caption images.\",\n    id: \"fancyfeast/joy-caption-beta-one\"\n  }],\n  summary: \"Image to text models output a text from a given image. Image captioning or optical character recognition can be considered as the most common applications of image to text.\",\n  widgetModels: [\"Salesforce/blip-image-captioning-large\"],\n  youtubeId: \"\"\n};\nexport default taskData;","map":{"version":3,"names":["taskData","datasets","description","id","demo","inputs","filename","type","outputs","label","content","metrics","models","spaces","summary","widgetModels","youtubeId"],"sources":["/Users/agmacbook/Documents/Courses/Meta - Full Stack/Exercises/meta_fullstack_exercises/6_react_basics/12_review/13_chef_claude/node_modules/@huggingface/tasks/dist/esm/tasks/image-to-text/data.js"],"sourcesContent":["const taskData = {\n    datasets: [\n        {\n            // TODO write proper description\n            description: \"Dataset from 12M image-text of Reddit\",\n            id: \"red_caps\",\n        },\n        {\n            // TODO write proper description\n            description: \"Dataset from 3.3M images of Google\",\n            id: \"datasets/conceptual_captions\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"savanna.jpg\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Detailed description\",\n                content: \"a herd of giraffes and zebras grazing in a field\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Strong OCR model.\",\n            id: \"allenai/olmOCR-7B-0725\",\n        },\n        {\n            description: \"Powerful image captioning model.\",\n            id: \"fancyfeast/llama-joycaption-beta-one-hf-llava\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"SVG generator app from images.\",\n            id: \"multimodalart/OmniSVG-3B\",\n        },\n        {\n            description: \"An application that converts documents to markdown.\",\n            id: \"numind/NuMarkdown-8B-Thinking\",\n        },\n        {\n            description: \"An application that can caption images.\",\n            id: \"fancyfeast/joy-caption-beta-one\",\n        },\n    ],\n    summary: \"Image to text models output a text from a given image. Image captioning or optical character recognition can be considered as the most common applications of image to text.\",\n    widgetModels: [\"Salesforce/blip-image-captioning-large\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n"],"mappings":"AAAA,MAAMA,QAAQ,GAAG;EACbC,QAAQ,EAAE,CACN;IACI;IACAC,WAAW,EAAE,uCAAuC;IACpDC,EAAE,EAAE;EACR,CAAC,EACD;IACI;IACAD,WAAW,EAAE,oCAAoC;IACjDC,EAAE,EAAE;EACR,CAAC,CACJ;EACDC,IAAI,EAAE;IACFC,MAAM,EAAE,CACJ;MACIC,QAAQ,EAAE,aAAa;MACvBC,IAAI,EAAE;IACV,CAAC,CACJ;IACDC,OAAO,EAAE,CACL;MACIC,KAAK,EAAE,sBAAsB;MAC7BC,OAAO,EAAE,kDAAkD;MAC3DH,IAAI,EAAE;IACV,CAAC;EAET,CAAC;EACDI,OAAO,EAAE,EAAE;EACXC,MAAM,EAAE,CACJ;IACIV,WAAW,EAAE,mBAAmB;IAChCC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,kCAAkC;IAC/CC,EAAE,EAAE;EACR,CAAC,CACJ;EACDU,MAAM,EAAE,CACJ;IACIX,WAAW,EAAE,gCAAgC;IAC7CC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,qDAAqD;IAClEC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,yCAAyC;IACtDC,EAAE,EAAE;EACR,CAAC,CACJ;EACDW,OAAO,EAAE,8KAA8K;EACvLC,YAAY,EAAE,CAAC,wCAAwC,CAAC;EACxDC,SAAS,EAAE;AACf,CAAC;AACD,eAAehB,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}