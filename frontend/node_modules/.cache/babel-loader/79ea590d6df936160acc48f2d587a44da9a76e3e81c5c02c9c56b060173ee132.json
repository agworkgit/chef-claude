{"ast":null,"code":"const taskData = {\n  datasets: [{\n    description: \"RedCaps is a large-scale dataset of 12M image-text pairs collected from Reddit.\",\n    id: \"red_caps\"\n  }, {\n    description: \"Conceptual Captions is a dataset consisting of ~3.3M images annotated with captions.\",\n    id: \"conceptual_captions\"\n  }, {\n    description: \"12M image-caption pairs.\",\n    id: \"Spawning/PD12M\"\n  }],\n  demo: {\n    inputs: [{\n      label: \"Input\",\n      content: \"A city above clouds, pastel colors, Victorian style\",\n      type: \"text\"\n    }],\n    outputs: [{\n      filename: \"image.jpeg\",\n      type: \"img\"\n    }]\n  },\n  metrics: [{\n    description: \"The Inception Score (IS) measure assesses diversity and meaningfulness. It uses a generated image sample to predict its label. A higher score signifies more diverse and meaningful images.\",\n    id: \"IS\"\n  }, {\n    description: \"The Fréchet Inception Distance (FID) calculates the distance between distributions between synthetic and real samples. A lower FID score indicates better similarity between the distributions of real and generated images.\",\n    id: \"FID\"\n  }, {\n    description: \"R-precision assesses how the generated image aligns with the provided text description. It uses the generated images as queries to retrieve relevant text descriptions. The top 'r' relevant descriptions are selected and used to calculate R-precision as r/R, where 'R' is the number of ground truth descriptions associated with the generated images. A higher R-precision value indicates a better model.\",\n    id: \"R-Precision\"\n  }],\n  models: [{\n    description: \"One of the most powerful image generation models that can generate realistic outputs.\",\n    id: \"black-forest-labs/FLUX.1-Krea-dev\"\n  }, {\n    description: \"A powerful image generation model.\",\n    id: \"Qwen/Qwen-Image\"\n  }, {\n    description: \"Powerful and fast image generation model.\",\n    id: \"ByteDance/SDXL-Lightning\"\n  }, {\n    description: \"A powerful text-to-image model.\",\n    id: \"ByteDance/Hyper-SD\"\n  }],\n  spaces: [{\n    description: \"A powerful text-to-image application.\",\n    id: \"stabilityai/stable-diffusion-3-medium\"\n  }, {\n    description: \"A text-to-image application to generate comics.\",\n    id: \"jbilcke-hf/ai-comic-factory\"\n  }, {\n    description: \"An application to match multiple custom image generation models.\",\n    id: \"multimodalart/flux-lora-lab\"\n  }, {\n    description: \"A powerful yet very fast image generation application.\",\n    id: \"latent-consistency/lcm-lora-for-sdxl\"\n  }, {\n    description: \"A gallery to explore various text-to-image models.\",\n    id: \"multimodalart/LoraTheExplorer\"\n  }, {\n    description: \"An application for `text-to-image`, `image-to-image` and image inpainting.\",\n    id: \"ArtGAN/Stable-Diffusion-ControlNet-WebUI\"\n  }, {\n    description: \"An application to generate realistic images given photos of a person and a prompt.\",\n    id: \"InstantX/InstantID\"\n  }],\n  summary: \"Text-to-image is the task of generating images from input text. These pipelines can also be used to modify and edit images based on text prompts.\",\n  widgetModels: [\"black-forest-labs/FLUX.1-dev\"],\n  youtubeId: \"\"\n};\nexport default taskData;","map":{"version":3,"names":["taskData","datasets","description","id","demo","inputs","label","content","type","outputs","filename","metrics","models","spaces","summary","widgetModels","youtubeId"],"sources":["/Users/agmacbook/Documents/Courses/Meta - Full Stack/Exercises/meta_fullstack_exercises/6_react_basics/12_review/13_chef_claude/node_modules/@huggingface/tasks/dist/esm/tasks/text-to-image/data.js"],"sourcesContent":["const taskData = {\n    datasets: [\n        {\n            description: \"RedCaps is a large-scale dataset of 12M image-text pairs collected from Reddit.\",\n            id: \"red_caps\",\n        },\n        {\n            description: \"Conceptual Captions is a dataset consisting of ~3.3M images annotated with captions.\",\n            id: \"conceptual_captions\",\n        },\n        {\n            description: \"12M image-caption pairs.\",\n            id: \"Spawning/PD12M\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"A city above clouds, pastel colors, Victorian style\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"image.jpeg\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The Inception Score (IS) measure assesses diversity and meaningfulness. It uses a generated image sample to predict its label. A higher score signifies more diverse and meaningful images.\",\n            id: \"IS\",\n        },\n        {\n            description: \"The Fréchet Inception Distance (FID) calculates the distance between distributions between synthetic and real samples. A lower FID score indicates better similarity between the distributions of real and generated images.\",\n            id: \"FID\",\n        },\n        {\n            description: \"R-precision assesses how the generated image aligns with the provided text description. It uses the generated images as queries to retrieve relevant text descriptions. The top 'r' relevant descriptions are selected and used to calculate R-precision as r/R, where 'R' is the number of ground truth descriptions associated with the generated images. A higher R-precision value indicates a better model.\",\n            id: \"R-Precision\",\n        },\n    ],\n    models: [\n        {\n            description: \"One of the most powerful image generation models that can generate realistic outputs.\",\n            id: \"black-forest-labs/FLUX.1-Krea-dev\",\n        },\n        {\n            description: \"A powerful image generation model.\",\n            id: \"Qwen/Qwen-Image\",\n        },\n        {\n            description: \"Powerful and fast image generation model.\",\n            id: \"ByteDance/SDXL-Lightning\",\n        },\n        {\n            description: \"A powerful text-to-image model.\",\n            id: \"ByteDance/Hyper-SD\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A powerful text-to-image application.\",\n            id: \"stabilityai/stable-diffusion-3-medium\",\n        },\n        {\n            description: \"A text-to-image application to generate comics.\",\n            id: \"jbilcke-hf/ai-comic-factory\",\n        },\n        {\n            description: \"An application to match multiple custom image generation models.\",\n            id: \"multimodalart/flux-lora-lab\",\n        },\n        {\n            description: \"A powerful yet very fast image generation application.\",\n            id: \"latent-consistency/lcm-lora-for-sdxl\",\n        },\n        {\n            description: \"A gallery to explore various text-to-image models.\",\n            id: \"multimodalart/LoraTheExplorer\",\n        },\n        {\n            description: \"An application for `text-to-image`, `image-to-image` and image inpainting.\",\n            id: \"ArtGAN/Stable-Diffusion-ControlNet-WebUI\",\n        },\n        {\n            description: \"An application to generate realistic images given photos of a person and a prompt.\",\n            id: \"InstantX/InstantID\",\n        },\n    ],\n    summary: \"Text-to-image is the task of generating images from input text. These pipelines can also be used to modify and edit images based on text prompts.\",\n    widgetModels: [\"black-forest-labs/FLUX.1-dev\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n"],"mappings":"AAAA,MAAMA,QAAQ,GAAG;EACbC,QAAQ,EAAE,CACN;IACIC,WAAW,EAAE,iFAAiF;IAC9FC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,sFAAsF;IACnGC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,0BAA0B;IACvCC,EAAE,EAAE;EACR,CAAC,CACJ;EACDC,IAAI,EAAE;IACFC,MAAM,EAAE,CACJ;MACIC,KAAK,EAAE,OAAO;MACdC,OAAO,EAAE,qDAAqD;MAC9DC,IAAI,EAAE;IACV,CAAC,CACJ;IACDC,OAAO,EAAE,CACL;MACIC,QAAQ,EAAE,YAAY;MACtBF,IAAI,EAAE;IACV,CAAC;EAET,CAAC;EACDG,OAAO,EAAE,CACL;IACIT,WAAW,EAAE,6LAA6L;IAC1MC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,8NAA8N;IAC3OC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,kZAAkZ;IAC/ZC,EAAE,EAAE;EACR,CAAC,CACJ;EACDS,MAAM,EAAE,CACJ;IACIV,WAAW,EAAE,uFAAuF;IACpGC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,oCAAoC;IACjDC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,2CAA2C;IACxDC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,iCAAiC;IAC9CC,EAAE,EAAE;EACR,CAAC,CACJ;EACDU,MAAM,EAAE,CACJ;IACIX,WAAW,EAAE,uCAAuC;IACpDC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,iDAAiD;IAC9DC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,kEAAkE;IAC/EC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,wDAAwD;IACrEC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,oDAAoD;IACjEC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,4EAA4E;IACzFC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,oFAAoF;IACjGC,EAAE,EAAE;EACR,CAAC,CACJ;EACDW,OAAO,EAAE,mJAAmJ;EAC5JC,YAAY,EAAE,CAAC,8BAA8B,CAAC;EAC9CC,SAAS,EAAE;AACf,CAAC;AACD,eAAehB,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}