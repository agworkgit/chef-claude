{"ast":null,"code":"const taskData = {\n  datasets: [{\n    description: \"512-element X-vector embeddings of speakers from CMU ARCTIC dataset.\",\n    id: \"Matthijs/cmu-arctic-xvectors\"\n  }],\n  demo: {\n    inputs: [{\n      filename: \"input.wav\",\n      type: \"audio\"\n    }],\n    outputs: [{\n      filename: \"label-0.wav\",\n      type: \"audio\"\n    }, {\n      filename: \"label-1.wav\",\n      type: \"audio\"\n    }]\n  },\n  metrics: [{\n    description: \"The Signal-to-Noise ratio is the relationship between the target signal level and the background noise level. It is calculated as the logarithm of the target signal divided by the background noise, in decibels.\",\n    id: \"snri\"\n  }, {\n    description: \"The Signal-to-Distortion ratio is the relationship between the target signal and the sum of noise, interference, and artifact errors\",\n    id: \"sdri\"\n  }],\n  models: [{\n    description: \"A speech enhancement model.\",\n    id: \"ResembleAI/resemble-enhance\"\n  }, {\n    description: \"A model that can change the voice in a speech recording.\",\n    id: \"microsoft/speecht5_vc\"\n  }],\n  spaces: [{\n    description: \"An application for speech separation.\",\n    id: \"younver/speechbrain-speech-separation\"\n  }, {\n    description: \"An application for audio style transfer.\",\n    id: \"nakas/audio-diffusion_style_transfer\"\n  }],\n  summary: \"Audio-to-Audio is a family of tasks in which the input is an audio and the output is one or multiple generated audios. Some example tasks are speech enhancement and source separation.\",\n  widgetModels: [\"speechbrain/sepformer-wham\"],\n  youtubeId: \"iohj7nCCYoM\"\n};\nexport default taskData;","map":{"version":3,"names":["taskData","datasets","description","id","demo","inputs","filename","type","outputs","metrics","models","spaces","summary","widgetModels","youtubeId"],"sources":["/Users/agmacbook/Documents/Courses/Meta - Full Stack/Exercises/meta_fullstack_exercises/6_react_basics/12_review/13_chef_claude/node_modules/@huggingface/tasks/dist/esm/tasks/audio-to-audio/data.js"],"sourcesContent":["const taskData = {\n    datasets: [\n        {\n            description: \"512-element X-vector embeddings of speakers from CMU ARCTIC dataset.\",\n            id: \"Matthijs/cmu-arctic-xvectors\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"input.wav\",\n                type: \"audio\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"label-0.wav\",\n                type: \"audio\",\n            },\n            {\n                filename: \"label-1.wav\",\n                type: \"audio\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The Signal-to-Noise ratio is the relationship between the target signal level and the background noise level. It is calculated as the logarithm of the target signal divided by the background noise, in decibels.\",\n            id: \"snri\",\n        },\n        {\n            description: \"The Signal-to-Distortion ratio is the relationship between the target signal and the sum of noise, interference, and artifact errors\",\n            id: \"sdri\",\n        },\n    ],\n    models: [\n        {\n            description: \"A speech enhancement model.\",\n            id: \"ResembleAI/resemble-enhance\",\n        },\n        {\n            description: \"A model that can change the voice in a speech recording.\",\n            id: \"microsoft/speecht5_vc\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application for speech separation.\",\n            id: \"younver/speechbrain-speech-separation\",\n        },\n        {\n            description: \"An application for audio style transfer.\",\n            id: \"nakas/audio-diffusion_style_transfer\",\n        },\n    ],\n    summary: \"Audio-to-Audio is a family of tasks in which the input is an audio and the output is one or multiple generated audios. Some example tasks are speech enhancement and source separation.\",\n    widgetModels: [\"speechbrain/sepformer-wham\"],\n    youtubeId: \"iohj7nCCYoM\",\n};\nexport default taskData;\n"],"mappings":"AAAA,MAAMA,QAAQ,GAAG;EACbC,QAAQ,EAAE,CACN;IACIC,WAAW,EAAE,sEAAsE;IACnFC,EAAE,EAAE;EACR,CAAC,CACJ;EACDC,IAAI,EAAE;IACFC,MAAM,EAAE,CACJ;MACIC,QAAQ,EAAE,WAAW;MACrBC,IAAI,EAAE;IACV,CAAC,CACJ;IACDC,OAAO,EAAE,CACL;MACIF,QAAQ,EAAE,aAAa;MACvBC,IAAI,EAAE;IACV,CAAC,EACD;MACID,QAAQ,EAAE,aAAa;MACvBC,IAAI,EAAE;IACV,CAAC;EAET,CAAC;EACDE,OAAO,EAAE,CACL;IACIP,WAAW,EAAE,oNAAoN;IACjOC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,sIAAsI;IACnJC,EAAE,EAAE;EACR,CAAC,CACJ;EACDO,MAAM,EAAE,CACJ;IACIR,WAAW,EAAE,6BAA6B;IAC1CC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,0DAA0D;IACvEC,EAAE,EAAE;EACR,CAAC,CACJ;EACDQ,MAAM,EAAE,CACJ;IACIT,WAAW,EAAE,uCAAuC;IACpDC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,0CAA0C;IACvDC,EAAE,EAAE;EACR,CAAC,CACJ;EACDS,OAAO,EAAE,yLAAyL;EAClMC,YAAY,EAAE,CAAC,4BAA4B,CAAC;EAC5CC,SAAS,EAAE;AACf,CAAC;AACD,eAAed,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}