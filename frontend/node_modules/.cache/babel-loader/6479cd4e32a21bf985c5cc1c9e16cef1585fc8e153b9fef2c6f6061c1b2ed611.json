{"ast":null,"code":"const taskData = {\n  datasets: [{\n    description: \"A benchmark of 10 different audio tasks.\",\n    id: \"s3prl/superb\"\n  }, {\n    description: \"A dataset of YouTube clips and their sound categories.\",\n    id: \"agkphysics/AudioSet\"\n  }],\n  demo: {\n    inputs: [{\n      filename: \"audio.wav\",\n      type: \"audio\"\n    }],\n    outputs: [{\n      data: [{\n        label: \"Up\",\n        score: 0.2\n      }, {\n        label: \"Down\",\n        score: 0.8\n      }],\n      type: \"chart\"\n    }]\n  },\n  metrics: [{\n    description: \"\",\n    id: \"accuracy\"\n  }, {\n    description: \"\",\n    id: \"recall\"\n  }, {\n    description: \"\",\n    id: \"precision\"\n  }, {\n    description: \"\",\n    id: \"f1\"\n  }],\n  models: [{\n    description: \"An easy-to-use model for command recognition.\",\n    id: \"speechbrain/google_speech_command_xvector\"\n  }, {\n    description: \"An emotion recognition model.\",\n    id: \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n  }, {\n    description: \"A language identification model.\",\n    id: \"facebook/mms-lid-126\"\n  }],\n  spaces: [{\n    description: \"An application that can classify music into different genre.\",\n    id: \"kurianbenoy/audioclassification\"\n  }],\n  summary: \"Audio classification is the task of assigning a label or class to a given audio. It can be used for recognizing which command a user is giving or the emotion of a statement, as well as identifying a speaker.\",\n  widgetModels: [\"MIT/ast-finetuned-audioset-10-10-0.4593\"],\n  youtubeId: \"KWwzcmG98Ds\"\n};\nexport default taskData;","map":{"version":3,"names":["taskData","datasets","description","id","demo","inputs","filename","type","outputs","data","label","score","metrics","models","spaces","summary","widgetModels","youtubeId"],"sources":["/Users/agmacbook/Documents/Courses/Meta - Full Stack/Exercises/meta_fullstack_exercises/6_react_basics/12_review/13_chef_claude/node_modules/@huggingface/tasks/dist/esm/tasks/audio-classification/data.js"],"sourcesContent":["const taskData = {\n    datasets: [\n        {\n            description: \"A benchmark of 10 different audio tasks.\",\n            id: \"s3prl/superb\",\n        },\n        {\n            description: \"A dataset of YouTube clips and their sound categories.\",\n            id: \"agkphysics/AudioSet\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"audio.wav\",\n                type: \"audio\",\n            },\n        ],\n        outputs: [\n            {\n                data: [\n                    {\n                        label: \"Up\",\n                        score: 0.2,\n                    },\n                    {\n                        label: \"Down\",\n                        score: 0.8,\n                    },\n                ],\n                type: \"chart\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"accuracy\",\n        },\n        {\n            description: \"\",\n            id: \"recall\",\n        },\n        {\n            description: \"\",\n            id: \"precision\",\n        },\n        {\n            description: \"\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            description: \"An easy-to-use model for command recognition.\",\n            id: \"speechbrain/google_speech_command_xvector\",\n        },\n        {\n            description: \"An emotion recognition model.\",\n            id: \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\",\n        },\n        {\n            description: \"A language identification model.\",\n            id: \"facebook/mms-lid-126\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can classify music into different genre.\",\n            id: \"kurianbenoy/audioclassification\",\n        },\n    ],\n    summary: \"Audio classification is the task of assigning a label or class to a given audio. It can be used for recognizing which command a user is giving or the emotion of a statement, as well as identifying a speaker.\",\n    widgetModels: [\"MIT/ast-finetuned-audioset-10-10-0.4593\"],\n    youtubeId: \"KWwzcmG98Ds\",\n};\nexport default taskData;\n"],"mappings":"AAAA,MAAMA,QAAQ,GAAG;EACbC,QAAQ,EAAE,CACN;IACIC,WAAW,EAAE,0CAA0C;IACvDC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,wDAAwD;IACrEC,EAAE,EAAE;EACR,CAAC,CACJ;EACDC,IAAI,EAAE;IACFC,MAAM,EAAE,CACJ;MACIC,QAAQ,EAAE,WAAW;MACrBC,IAAI,EAAE;IACV,CAAC,CACJ;IACDC,OAAO,EAAE,CACL;MACIC,IAAI,EAAE,CACF;QACIC,KAAK,EAAE,IAAI;QACXC,KAAK,EAAE;MACX,CAAC,EACD;QACID,KAAK,EAAE,MAAM;QACbC,KAAK,EAAE;MACX,CAAC,CACJ;MACDJ,IAAI,EAAE;IACV,CAAC;EAET,CAAC;EACDK,OAAO,EAAE,CACL;IACIV,WAAW,EAAE,EAAE;IACfC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,EAAE;IACfC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,EAAE;IACfC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,EAAE;IACfC,EAAE,EAAE;EACR,CAAC,CACJ;EACDU,MAAM,EAAE,CACJ;IACIX,WAAW,EAAE,+CAA+C;IAC5DC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,+BAA+B;IAC5CC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,kCAAkC;IAC/CC,EAAE,EAAE;EACR,CAAC,CACJ;EACDW,MAAM,EAAE,CACJ;IACIZ,WAAW,EAAE,8DAA8D;IAC3EC,EAAE,EAAE;EACR,CAAC,CACJ;EACDY,OAAO,EAAE,iNAAiN;EAC1NC,YAAY,EAAE,CAAC,yCAAyC,CAAC;EACzDC,SAAS,EAAE;AACf,CAAC;AACD,eAAejB,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}