{"ast":null,"code":"const taskData = {\n  datasets: [{\n    description: \"Dataset with detailed annotations for training and benchmarking video instance editing.\",\n    id: \"suimu/VIRESET\"\n  }, {\n    description: \"Dataset to evaluate models on long video generation and understanding.\",\n    id: \"zhangsh2001/LongV-EVAL\"\n  }, {\n    description: \"Collection of 104 demo videos from the SeedVR/SeedVR2 series showcasing model outputs.\",\n    id: \"Iceclear/SeedVR_VideoDemos\"\n  }],\n  demo: {\n    inputs: [{\n      filename: \"input.gif\",\n      type: \"img\"\n    }],\n    outputs: [{\n      filename: \"output.gif\",\n      type: \"img\"\n    }]\n  },\n  metrics: [],\n  models: [{\n    description: \"Model for editing outfits, character, and scenery in videos.\",\n    id: \"decart-ai/Lucy-Edit-Dev\"\n  }, {\n    description: \"Framework that uses 3D mesh proxies for precise, consistent video editing.\",\n    id: \"LeoLau/Shape-for-Motion\"\n  }, {\n    description: \"Model for generating physics-aware videos from input videos and control conditions.\",\n    id: \"nvidia/Cosmos-Transfer2.5-2B\"\n  }, {\n    description: \"A model to upscale videos at input, designed for seamless use with ComfyUI.\",\n    id: \"numz/SeedVR2_comfyUI\"\n  }],\n  spaces: [{\n    description: \"Interactive demo space for Lucy-Edit-Dev video editing.\",\n    id: \"decart-ai/lucy-edit-dev\"\n  }, {\n    description: \"Demo space for SeedVR2-3B showcasing video upscaling and restoration.\",\n    id: \"ByteDance-Seed/SeedVR2-3B\"\n  }],\n  summary: \"Video-to-video models take one or more videos as input and generate new videos as output. They can enhance quality, interpolate frames, modify styles, or create new motion dynamics, enabling creative applications, video production, and research.\",\n  widgetModels: [],\n  youtubeId: \"\"\n};\nexport default taskData;","map":{"version":3,"names":["taskData","datasets","description","id","demo","inputs","filename","type","outputs","metrics","models","spaces","summary","widgetModels","youtubeId"],"sources":["/Users/agmacbook/Documents/Courses/Meta - Full Stack/Exercises/meta_fullstack_exercises/6_react_basics/12_review/13_chef_claude/node_modules/@huggingface/tasks/dist/esm/tasks/video-to-video/data.js"],"sourcesContent":["const taskData = {\n    datasets: [\n        {\n            description: \"Dataset with detailed annotations for training and benchmarking video instance editing.\",\n            id: \"suimu/VIRESET\",\n        },\n        {\n            description: \"Dataset to evaluate models on long video generation and understanding.\",\n            id: \"zhangsh2001/LongV-EVAL\",\n        },\n        {\n            description: \"Collection of 104 demo videos from the SeedVR/SeedVR2 series showcasing model outputs.\",\n            id: \"Iceclear/SeedVR_VideoDemos\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"input.gif\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"output.gif\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Model for editing outfits, character, and scenery in videos.\",\n            id: \"decart-ai/Lucy-Edit-Dev\",\n        },\n        {\n            description: \"Framework that uses 3D mesh proxies for precise, consistent video editing.\",\n            id: \"LeoLau/Shape-for-Motion\",\n        },\n        {\n            description: \"Model for generating physics-aware videos from input videos and control conditions.\",\n            id: \"nvidia/Cosmos-Transfer2.5-2B\",\n        },\n        {\n            description: \"A model to upscale videos at input, designed for seamless use with ComfyUI.\",\n            id: \"numz/SeedVR2_comfyUI\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"Interactive demo space for Lucy-Edit-Dev video editing.\",\n            id: \"decart-ai/lucy-edit-dev\",\n        },\n        {\n            description: \"Demo space for SeedVR2-3B showcasing video upscaling and restoration.\",\n            id: \"ByteDance-Seed/SeedVR2-3B\",\n        },\n    ],\n    summary: \"Video-to-video models take one or more videos as input and generate new videos as output. They can enhance quality, interpolate frames, modify styles, or create new motion dynamics, enabling creative applications, video production, and research.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n"],"mappings":"AAAA,MAAMA,QAAQ,GAAG;EACbC,QAAQ,EAAE,CACN;IACIC,WAAW,EAAE,yFAAyF;IACtGC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,wEAAwE;IACrFC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,wFAAwF;IACrGC,EAAE,EAAE;EACR,CAAC,CACJ;EACDC,IAAI,EAAE;IACFC,MAAM,EAAE,CACJ;MACIC,QAAQ,EAAE,WAAW;MACrBC,IAAI,EAAE;IACV,CAAC,CACJ;IACDC,OAAO,EAAE,CACL;MACIF,QAAQ,EAAE,YAAY;MACtBC,IAAI,EAAE;IACV,CAAC;EAET,CAAC;EACDE,OAAO,EAAE,EAAE;EACXC,MAAM,EAAE,CACJ;IACIR,WAAW,EAAE,8DAA8D;IAC3EC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,4EAA4E;IACzFC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,qFAAqF;IAClGC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,6EAA6E;IAC1FC,EAAE,EAAE;EACR,CAAC,CACJ;EACDQ,MAAM,EAAE,CACJ;IACIT,WAAW,EAAE,yDAAyD;IACtEC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,uEAAuE;IACpFC,EAAE,EAAE;EACR,CAAC,CACJ;EACDS,OAAO,EAAE,uPAAuP;EAChQC,YAAY,EAAE,EAAE;EAChBC,SAAS,EAAE;AACf,CAAC;AACD,eAAed,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}