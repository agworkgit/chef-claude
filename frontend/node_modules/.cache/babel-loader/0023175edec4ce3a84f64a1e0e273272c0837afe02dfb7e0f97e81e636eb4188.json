{"ast":null,"code":"const taskData = {\n  datasets: [{\n    description: \"Bing queries with relevant passages from various web sources.\",\n    id: \"microsoft/ms_marco\"\n  }],\n  demo: {\n    inputs: [{\n      label: \"Source sentence\",\n      content: \"Machine learning is so easy.\",\n      type: \"text\"\n    }, {\n      label: \"Sentences to compare to\",\n      content: \"Deep learning is so straightforward.\",\n      type: \"text\"\n    }, {\n      label: \"\",\n      content: \"This is so difficult, like rocket science.\",\n      type: \"text\"\n    }, {\n      label: \"\",\n      content: \"I can't believe how much I struggled with this.\",\n      type: \"text\"\n    }],\n    outputs: [{\n      type: \"chart\",\n      data: [{\n        label: \"Deep learning is so straightforward.\",\n        score: 2.2006407\n      }, {\n        label: \"This is so difficult, like rocket science.\",\n        score: -6.2634873\n      }, {\n        label: \"I can't believe how much I struggled with this.\",\n        score: -10.251488\n      }]\n    }]\n  },\n  metrics: [{\n    description: \"Discounted Cumulative Gain (DCG) measures the gain, or usefulness, of search results discounted by their position. The normalization is done by dividing the DCG by the ideal DCG, which is the DCG of the perfect ranking.\",\n    id: \"Normalized Discounted Cumulative Gain\"\n  }, {\n    description: \"Reciprocal Rank is a measure used to rank the relevancy of documents given a set of documents. Reciprocal Rank is the reciprocal of the rank of the document retrieved, meaning, if the rank is 3, the Reciprocal Rank is 0.33. If the rank is 1, the Reciprocal Rank is 1\",\n    id: \"Mean Reciprocal Rank\"\n  }, {\n    description: \"Mean Average Precision (mAP) is the overall average of the Average Precision (AP) values, where AP is the Area Under the PR Curve (AUC-PR)\",\n    id: \"Mean Average Precision\"\n  }],\n  models: [{\n    description: \"An extremely efficient text ranking model trained on a web search dataset.\",\n    id: \"cross-encoder/ms-marco-MiniLM-L6-v2\"\n  }, {\n    description: \"A strong multilingual text reranker model.\",\n    id: \"Alibaba-NLP/gte-multilingual-reranker-base\"\n  }, {\n    description: \"An efficient text ranking model that punches above its weight.\",\n    id: \"Alibaba-NLP/gte-reranker-modernbert-base\"\n  }],\n  spaces: [],\n  summary: \"Text Ranking is the task of ranking a set of texts based on their relevance to a query. Text ranking models are trained on large datasets of queries and relevant documents to learn how to rank documents based on their relevance to the query. This task is particularly useful for search engines and information retrieval systems.\",\n  widgetModels: [\"cross-encoder/ms-marco-MiniLM-L6-v2\"],\n  youtubeId: \"\"\n};\nexport default taskData;","map":{"version":3,"names":["taskData","datasets","description","id","demo","inputs","label","content","type","outputs","data","score","metrics","models","spaces","summary","widgetModels","youtubeId"],"sources":["/Users/agmacbook/Documents/Courses/Meta - Full Stack/Exercises/meta_fullstack_exercises/6_react_basics/12_review/13_chef_claude/node_modules/@huggingface/tasks/dist/esm/tasks/text-ranking/data.js"],"sourcesContent":["const taskData = {\n    datasets: [\n        {\n            description: \"Bing queries with relevant passages from various web sources.\",\n            id: \"microsoft/ms_marco\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Source sentence\",\n                content: \"Machine learning is so easy.\",\n                type: \"text\",\n            },\n            {\n                label: \"Sentences to compare to\",\n                content: \"Deep learning is so straightforward.\",\n                type: \"text\",\n            },\n            {\n                label: \"\",\n                content: \"This is so difficult, like rocket science.\",\n                type: \"text\",\n            },\n            {\n                label: \"\",\n                content: \"I can't believe how much I struggled with this.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"Deep learning is so straightforward.\",\n                        score: 2.2006407,\n                    },\n                    {\n                        label: \"This is so difficult, like rocket science.\",\n                        score: -6.2634873,\n                    },\n                    {\n                        label: \"I can't believe how much I struggled with this.\",\n                        score: -10.251488,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Discounted Cumulative Gain (DCG) measures the gain, or usefulness, of search results discounted by their position. The normalization is done by dividing the DCG by the ideal DCG, which is the DCG of the perfect ranking.\",\n            id: \"Normalized Discounted Cumulative Gain\",\n        },\n        {\n            description: \"Reciprocal Rank is a measure used to rank the relevancy of documents given a set of documents. Reciprocal Rank is the reciprocal of the rank of the document retrieved, meaning, if the rank is 3, the Reciprocal Rank is 0.33. If the rank is 1, the Reciprocal Rank is 1\",\n            id: \"Mean Reciprocal Rank\",\n        },\n        {\n            description: \"Mean Average Precision (mAP) is the overall average of the Average Precision (AP) values, where AP is the Area Under the PR Curve (AUC-PR)\",\n            id: \"Mean Average Precision\",\n        },\n    ],\n    models: [\n        {\n            description: \"An extremely efficient text ranking model trained on a web search dataset.\",\n            id: \"cross-encoder/ms-marco-MiniLM-L6-v2\",\n        },\n        {\n            description: \"A strong multilingual text reranker model.\",\n            id: \"Alibaba-NLP/gte-multilingual-reranker-base\",\n        },\n        {\n            description: \"An efficient text ranking model that punches above its weight.\",\n            id: \"Alibaba-NLP/gte-reranker-modernbert-base\",\n        },\n    ],\n    spaces: [],\n    summary: \"Text Ranking is the task of ranking a set of texts based on their relevance to a query. Text ranking models are trained on large datasets of queries and relevant documents to learn how to rank documents based on their relevance to the query. This task is particularly useful for search engines and information retrieval systems.\",\n    widgetModels: [\"cross-encoder/ms-marco-MiniLM-L6-v2\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n"],"mappings":"AAAA,MAAMA,QAAQ,GAAG;EACbC,QAAQ,EAAE,CACN;IACIC,WAAW,EAAE,+DAA+D;IAC5EC,EAAE,EAAE;EACR,CAAC,CACJ;EACDC,IAAI,EAAE;IACFC,MAAM,EAAE,CACJ;MACIC,KAAK,EAAE,iBAAiB;MACxBC,OAAO,EAAE,8BAA8B;MACvCC,IAAI,EAAE;IACV,CAAC,EACD;MACIF,KAAK,EAAE,yBAAyB;MAChCC,OAAO,EAAE,sCAAsC;MAC/CC,IAAI,EAAE;IACV,CAAC,EACD;MACIF,KAAK,EAAE,EAAE;MACTC,OAAO,EAAE,4CAA4C;MACrDC,IAAI,EAAE;IACV,CAAC,EACD;MACIF,KAAK,EAAE,EAAE;MACTC,OAAO,EAAE,iDAAiD;MAC1DC,IAAI,EAAE;IACV,CAAC,CACJ;IACDC,OAAO,EAAE,CACL;MACID,IAAI,EAAE,OAAO;MACbE,IAAI,EAAE,CACF;QACIJ,KAAK,EAAE,sCAAsC;QAC7CK,KAAK,EAAE;MACX,CAAC,EACD;QACIL,KAAK,EAAE,4CAA4C;QACnDK,KAAK,EAAE,CAAC;MACZ,CAAC,EACD;QACIL,KAAK,EAAE,iDAAiD;QACxDK,KAAK,EAAE,CAAC;MACZ,CAAC;IAET,CAAC;EAET,CAAC;EACDC,OAAO,EAAE,CACL;IACIV,WAAW,EAAE,6NAA6N;IAC1OC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,4QAA4Q;IACzRC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,4IAA4I;IACzJC,EAAE,EAAE;EACR,CAAC,CACJ;EACDU,MAAM,EAAE,CACJ;IACIX,WAAW,EAAE,4EAA4E;IACzFC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,4CAA4C;IACzDC,EAAE,EAAE;EACR,CAAC,EACD;IACID,WAAW,EAAE,gEAAgE;IAC7EC,EAAE,EAAE;EACR,CAAC,CACJ;EACDW,MAAM,EAAE,EAAE;EACVC,OAAO,EAAE,0UAA0U;EACnVC,YAAY,EAAE,CAAC,qCAAqC,CAAC;EACrDC,SAAS,EAAE;AACf,CAAC;AACD,eAAejB,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}